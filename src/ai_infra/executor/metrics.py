"""Per-node metrics tracking for executor graph.

Phase 2.4.3: Track tokens, duration, and LLM calls per graph node.

This module provides:
- NodeMetrics dataclass for per-node statistics
- track_node_metrics decorator for instrumented nodes
- Helper functions for aggregating and formatting node metrics
"""

from __future__ import annotations

import time
from collections.abc import Callable
from dataclasses import dataclass, field
from functools import wraps
from typing import TYPE_CHECKING, Any, TypeVar

from ai_infra.logging import get_logger

if TYPE_CHECKING:
    from ai_infra.executor.state import ExecutorGraphState

logger = get_logger("executor.metrics")


# =============================================================================
# NodeMetrics Data Model
# =============================================================================


@dataclass
class NodeMetrics:
    """Metrics for a single graph node execution.

    Phase 2.4.3: Tracks tokens, duration, and LLM calls per node.

    Attributes:
        tokens_in: Input tokens consumed by this node.
        tokens_out: Output tokens generated by this node.
        duration_ms: Execution duration in milliseconds.
        llm_calls: Number of LLM calls made by this node.
        invocations: Number of times this node was invoked.
    """

    tokens_in: int = 0
    tokens_out: int = 0
    duration_ms: int = 0
    llm_calls: int = 0
    invocations: int = 0

    @property
    def total_tokens(self) -> int:
        """Total tokens (input + output)."""
        return self.tokens_in + self.tokens_out

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary for state storage."""
        return {
            "tokens_in": self.tokens_in,
            "tokens_out": self.tokens_out,
            "duration_ms": self.duration_ms,
            "llm_calls": self.llm_calls,
            "invocations": self.invocations,
            "total_tokens": self.total_tokens,
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> NodeMetrics:
        """Create from dictionary."""
        return cls(
            tokens_in=data.get("tokens_in", 0),
            tokens_out=data.get("tokens_out", 0),
            duration_ms=data.get("duration_ms", 0),
            llm_calls=data.get("llm_calls", 0),
            invocations=data.get("invocations", 0),
        )

    def merge(self, other: NodeMetrics) -> NodeMetrics:
        """Merge with another NodeMetrics (additive)."""
        return NodeMetrics(
            tokens_in=self.tokens_in + other.tokens_in,
            tokens_out=self.tokens_out + other.tokens_out,
            duration_ms=self.duration_ms + other.duration_ms,
            llm_calls=self.llm_calls + other.llm_calls,
            invocations=self.invocations + other.invocations,
        )


# =============================================================================
# Metrics Aggregation
# =============================================================================


@dataclass
class AggregatedNodeMetrics:
    """Aggregated metrics across all nodes.

    Provides summary statistics and per-node breakdown.
    """

    node_metrics: dict[str, NodeMetrics] = field(default_factory=dict)

    @property
    def total_tokens(self) -> int:
        """Total tokens across all nodes."""
        return sum(m.total_tokens for m in self.node_metrics.values())

    @property
    def total_tokens_in(self) -> int:
        """Total input tokens across all nodes."""
        return sum(m.tokens_in for m in self.node_metrics.values())

    @property
    def total_tokens_out(self) -> int:
        """Total output tokens across all nodes."""
        return sum(m.tokens_out for m in self.node_metrics.values())

    @property
    def total_duration_ms(self) -> int:
        """Total duration across all nodes."""
        return sum(m.duration_ms for m in self.node_metrics.values())

    @property
    def total_llm_calls(self) -> int:
        """Total LLM calls across all nodes."""
        return sum(m.llm_calls for m in self.node_metrics.values())

    def get_node_percentage(self, node_name: str) -> float:
        """Get percentage of total tokens used by a node."""
        if self.total_tokens == 0:
            return 0.0
        node = self.node_metrics.get(node_name)
        if not node:
            return 0.0
        return (node.total_tokens / self.total_tokens) * 100

    def to_dict(self) -> dict[str, Any]:
        """Convert to dictionary."""
        return {
            "nodes": {name: m.to_dict() for name, m in self.node_metrics.items()},
            "totals": {
                "tokens_in": self.total_tokens_in,
                "tokens_out": self.total_tokens_out,
                "total_tokens": self.total_tokens,
                "duration_ms": self.total_duration_ms,
                "llm_calls": self.total_llm_calls,
            },
        }

    @classmethod
    def from_dict(cls, data: dict[str, Any]) -> AggregatedNodeMetrics:
        """Create from dictionary."""
        nodes = data.get("nodes", {})
        return cls(node_metrics={name: NodeMetrics.from_dict(m) for name, m in nodes.items()})

    def format_breakdown(self) -> str:
        """Format per-node breakdown for display.

        Returns human-readable breakdown like:
        ```
        Per-Node Breakdown:
            build_context: 12,340 tokens (10%), 2,100ms
            execute_task:  98,200 tokens (78%), 38,000ms  <- Optimization target
            verify_task:   14,890 tokens (12%), 5,130ms
            checkpoint:    0 tokens, 1,000ms
        ```
        """
        if not self.node_metrics:
            return "No node metrics collected."

        lines = ["Per-Node Breakdown:"]

        # Sort by total tokens descending
        sorted_nodes = sorted(
            self.node_metrics.items(),
            key=lambda x: x[1].total_tokens,
            reverse=True,
        )

        # Find max node name length for alignment
        max_name_len = max(len(name) for name, _ in sorted_nodes)

        # Find highest token consumer for marker
        highest_tokens = max(m.total_tokens for _, m in sorted_nodes) if sorted_nodes else 0

        for name, metrics in sorted_nodes:
            pct = self.get_node_percentage(name)
            tokens_str = f"{metrics.total_tokens:,}"
            duration_str = f"{metrics.duration_ms:,}ms"

            # Add marker for highest consumer
            marker = ""
            if metrics.total_tokens == highest_tokens and metrics.total_tokens > 0:
                marker = "  <- Optimization target"

            line = (
                f"    {name:<{max_name_len}}: "
                f"{tokens_str:>10} tokens ({pct:>5.1f}%), "
                f"{duration_str:>10}"
                f"{marker}"
            )
            lines.append(line)

        return "\n".join(lines)


# =============================================================================
# Token Tracking Context
# =============================================================================


class TokenTracker:
    """Thread-local token tracking for LLM calls.

    This class provides a context for tracking tokens consumed during
    node execution. It should be used in conjunction with LLM callbacks.

    Note: This is a simplified implementation. In production, this would
    integrate with the LLM callback system to capture actual token usage.
    """

    _current_tokens_in: int = 0
    _current_tokens_out: int = 0
    _current_llm_calls: int = 0

    @classmethod
    def reset(cls) -> None:
        """Reset counters for a new tracking session."""
        cls._current_tokens_in = 0
        cls._current_tokens_out = 0
        cls._current_llm_calls = 0

    @classmethod
    def add_usage(
        cls,
        tokens_in: int = 0,
        tokens_out: int = 0,
        llm_calls: int = 0,
    ) -> None:
        """Add token usage from an LLM call."""
        cls._current_tokens_in += tokens_in
        cls._current_tokens_out += tokens_out
        cls._current_llm_calls += llm_calls

    @classmethod
    def get_usage(cls) -> tuple[int, int, int]:
        """Get current token usage (tokens_in, tokens_out, llm_calls)."""
        return cls._current_tokens_in, cls._current_tokens_out, cls._current_llm_calls


# =============================================================================
# Decorator for Node Metrics
# =============================================================================


F = TypeVar("F", bound=Callable[..., Any])


def track_node_metrics(node_name: str) -> Callable[[F], F]:
    """Decorator to track metrics for a graph node.

    Phase 2.4.3: Wraps node functions to track execution time and token usage.

    The decorator:
    1. Records start time before node execution
    2. Resets token tracker
    3. Executes the node
    4. Calculates duration and retrieves token usage
    5. Updates node_metrics in state

    Usage:
        @track_node_metrics("execute_task")
        async def execute_task_node(state, *, agent):
            ...

    Args:
        node_name: Name of the node for metrics collection.

    Returns:
        Decorated function that tracks metrics.
    """

    def decorator(func: F) -> F:
        @wraps(func)
        async def wrapper(
            state: ExecutorGraphState,
            **kwargs: Any,
        ) -> ExecutorGraphState:
            # Skip tracking if node_metrics not enabled
            if not state.get("enable_node_metrics", True):
                return await func(state, **kwargs)

            # Record start time
            start_time = time.perf_counter()

            # Reset token tracker for this node
            TokenTracker.reset()

            # Execute the node
            result = await func(state, **kwargs)

            # Calculate duration
            duration_ms = int((time.perf_counter() - start_time) * 1000)

            # Get token usage
            tokens_in, tokens_out, llm_calls = TokenTracker.get_usage()

            # Create metrics for this invocation
            new_metrics = NodeMetrics(
                tokens_in=tokens_in,
                tokens_out=tokens_out,
                duration_ms=duration_ms,
                llm_calls=llm_calls,
                invocations=1,
            )

            # Get existing node_metrics from result or state
            existing_metrics: dict[str, Any] = result.get(
                "node_metrics", state.get("node_metrics", {})
            )

            # Merge with existing metrics for this node
            if node_name in existing_metrics:
                existing = NodeMetrics.from_dict(existing_metrics[node_name])
                merged = existing.merge(new_metrics)
                existing_metrics[node_name] = merged.to_dict()
            else:
                existing_metrics[node_name] = new_metrics.to_dict()

            logger.debug(
                f"Node [{node_name}] completed: {duration_ms}ms, {tokens_in + tokens_out} tokens"
            )

            # Return result with updated metrics
            return {
                **result,
                "node_metrics": existing_metrics,
            }

        return wrapper  # type: ignore[return-value]

    return decorator


# =============================================================================
# Helper Functions
# =============================================================================


def aggregate_node_metrics(
    node_metrics: dict[str, Any] | None,
) -> AggregatedNodeMetrics:
    """Aggregate node metrics from state.

    Args:
        node_metrics: Raw node_metrics dict from state.

    Returns:
        Aggregated metrics with summary statistics.
    """
    if not node_metrics:
        return AggregatedNodeMetrics()

    return AggregatedNodeMetrics(
        node_metrics={name: NodeMetrics.from_dict(data) for name, data in node_metrics.items()}
    )


def format_run_summary_with_nodes(
    total_duration_ms: int,
    total_tokens: int,
    node_metrics: dict[str, Any] | None,
) -> str:
    """Format run summary with per-node breakdown.

    Phase 2.4.3: Enhanced summary output with node-level details.

    Args:
        total_duration_ms: Total run duration in milliseconds.
        total_tokens: Total tokens used.
        node_metrics: Raw node_metrics dict from state.

    Returns:
        Formatted summary string.
    """
    lines = [
        "Run Summary:",
        f"    Total Duration: {total_duration_ms:,}ms",
        f"    Total Tokens: {total_tokens:,}",
    ]

    if node_metrics:
        aggregated = aggregate_node_metrics(node_metrics)
        lines.append("")
        lines.append(aggregated.format_breakdown())

    return "\n".join(lines)
